---
title: "Rating Scale Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Norms (raw-to-T) lookup tables

This code template derives normalized T-scores from an input data file with multiple raw scores, including subscales and composite scores. Because the optimal normalization model may vary with different raw score distributions, the template processes only a single input file (i.e., data from a single rating-scale form, identified by a combination of age-range (e.g., "child") and rater (e.g., "parent). For projects with multiple forms that require separate raw-to-T lookup tables, we implement the template separately for each input file.

The output includes raw-to-T lookup tables in both generalized and print formats, as well as tables of demographic counts and raw score descriptive statistics. 

#### 1. Load packages, read data, initialize tokens for robust code

###### EXECUTABLE CODE
```{r norms-load, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(psych))
suppressMessages(library(bestNormalize))

urlRemote_path  <- "https://raw.githubusercontent.com/"
github_path <- "DSHerzberg/RATING-SCALE-ANALYSIS/master/INPUT-FILES/"
input_name <- "data-RS-sim-child-parent.csv"

item_prefix <- "cp"
scale_prefix <- "CP"
scale_suffix <- c("S1", "S2", "S3", "S4", "S5", "TOT")
age_range_name <- "child"
form_name <- "parent"
all_raw_range <- 10:200
TOT_raw_lower_bound <- 50
subscale_raw_upper_bound <- 40

assign(
  str_c("data", age_range_name, form_name, sep = "_"),
  suppressMessages(read_csv(url(
    str_c(urlRemote_path, github_path, input_name)
  ))) %>%
    mutate(across(
      contains(str_c(item_prefix, "i")),
      ~ case_when(
        .x == "never" ~ 1,
        .x == "occasionally" ~ 2,
        .x == "frequently" ~ 3,
        .x == "always" ~ 4
      )
    ))
)
```

###### COMMENTED SNIPPETS
Load packages for file path specification (`here`), data wrangling (`tidyverse`),  psychometric data simulation and analysis (`psych`), and normalization of raw score distributions (`bestNormalize`).
```{r norms-load, echo = 1:4, eval = F}
```
We write _robust_ templates that can be adapted to different projects with minimal copying-and-pasting of text. We facilitate this by providing object name placeholders, as vectors, for file paths, file and variable names (and their component sub-strings), score ranges, and other snippets of code that are re-used throughout the template. Note that in this example, we are reading an input file, consisting of simulated rating scale data, from a remote URL.
```{r norms-load, echo = 5:16, eval = F}
```
In a robust template, we create object names by concatenating placeholder vectors and explicit strings. Instead of the assignment operator `<--`, we use `base::assign()` to initialize these concatenated names. `assign()` takes two arguments, the desired name (concatenated with `stringr::str_c()`), and the code snippet that defines the object to be named.

As an example, `str_c("data", age_range_name, form_name, sep = "_")` returns the name `data_child_parent`, combining the file type description (`"data"`, provided as an explicit string) with the age-range (`age_range_name`) and rater (`form_name`) vectors. The combination of these latter two vectors identifies the form whose data is contained in the input file
```{r norms-load, echo = 19:20, eval = F}
```
The next snippet uses `dplyr::mutate(across())` to recode the item responses into numerical values. `across()` takes two arguments: a subset of columns to be processed, and a function to be applied to those columns. In this example, we subset the item response columns with the `tidyselect` helper `contains()`, providing as its argument a concatentated string that this appears _only_ in the names of the item response columns. We use `case_when()` to conditionally recode the cell values (`.x`) of these columns, recoding the input strings to numbers (e.g., `"never" ~ 1`).
```{r norms-load, echo = 24:31, eval = F}
```

<br>

#### 2. Determine optimal normalization model and calcuate normalized T-scores per case

###### EXECUTABLE CODE
```{r norms-model, eval = FALSE}
assign(str_c("data", age_range_name, form_name, "TOT", sep = "_"),
       suppressMessages(read_csv(url(
         str_c(urlRemote_path, github_path, input_name)
       ))) %>% 
         select(!!sym(str_c(scale_prefix, "TOT_raw"))) %>% 
         as_vector() %>% 
         set_names(NULL)
)

set.seed(12345)
TOT_nz_obj <- bestNormalize(data_child_parent_TOT)
TOT_nz_obj$chosen_transform
chosen_transform <- class(TOT_nz_obj$chosen_transform)[1]

raw_score_cols_list <-
  map(str_c(scale_prefix, scale_suffix),
      ~ get(str_c("data", age_range_name, form_name, sep = "_")) %>%
        pull(!!sym(str_c(.x, "_raw")))) %>% 
  set_names(str_c(scale_prefix, scale_suffix, "_raw"))


nzScore_perCase <- raw_score_cols_list %>% 
  map(~ get(chosen_transform)(.x)) %>% 
  map(~ tibble(pluck(.x, "x.t"), .name_repair = "universal")) %>% 
  bind_cols() %>%
  set_names(str_c(scale_suffix, "_nz")) 

ntScore_perCase <- map_dfc(scale_suffix,
                           ~
                             nzScore_perCase %>%
                             transmute(!!sym(str_c(
                               scale_prefix, .x, "_nt"
                             )) := round(!!sym(str_c(
                               .x, "_nz"
                             )) * 10) + 50)) %>%
  mutate(across(
    everything(),
    ~
      case_when(. < 40 ~ 40,
                . > 80 ~ 80,
                TRUE ~ .) %>%
      as.integer(.)
  ))

assign(
  str_c("data", age_range_name, form_name, "nt", sep = "_"),
  get(str_c("data", age_range_name, form_name, sep = "_")) %>% bind_cols(ntScore_perCase) %>%
    mutate(clin_status = 'typ',
           clin_dx = NA) %>%
    select(
      ID:region,
      clin_status,
      clin_dx,
      contains("raw"),
      contains("nt"),
      everything()
    )
)

write_csv(get(str_c(
  "data", age_range_name, form_name, "nt", sep = "_"
)),
here(str_c(
  "OUTPUT-FILES/TABLES/",
  str_c("nt-Scores-per-case",
        age_range_name,
        form_name,
        sep = "-"),
  ".csv"
)),
na = '')

get(str_c("data", age_range_name, form_name, "nt", sep = "_")) %>%
  select(contains("TOT_nt")) %>%
  as_vector() %>%
  MASS::truehist(.,
                 h = 1,
                 prob = FALSE,
                 xlab = "TOT_nt")
```
###### COMMENTED SNIPPETS
The `bestNormalize` package provides tools for selectng a normalization model and applying that model to a raw score distribution. For the latter step, the `bestNormalize()` function requires as input the raw score distribution formatted as a numerical vector.

As in previous steps, we use `assign()` to name objects with concatenated strings. To create the numerical vector required by `bestNormalize()`, we `select()` the column containing the raw total scores for (`TOT_raw`). Best practice suggests that we use a total or composite score for this purpose, because by definition it captures more of the sample variance than subscale scores that consist of fewer items. `select()` requires unquoted column names as input, which we fulfill by wrapping the concatenated column name (the quoted string returned by `str_c()`) in the unquoting function `!!sym()`.
```{r norms-model, echo = 1:8, eval = F}
```
