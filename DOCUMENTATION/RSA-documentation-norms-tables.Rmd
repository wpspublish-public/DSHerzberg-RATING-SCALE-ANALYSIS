---
title: "Rating Scale Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Norms (raw-to-T) lookup tables

This code template derives normalized T-scores from an input data file with multiple raw scores, including subscales and composite scores. Because the optimal normalization model may vary with different raw score distributions, the template processes only a single input file (i.e., data from a single rating-scale form, identified by a combination of age-range (e.g., "child") and rater (e.g., "parent"). For projects with multiple forms that require separate raw-to-T lookup tables, the recommended approach is to implement the template separately for each input file.

Output includes raw-to-T lookup tables in both generalized and print formats, as well as tables of demographic counts and raw score descriptive statistics. 

<br>

#### 1. Load packages, read data, initialize tokens for robust code

###### EXECUTABLE CODE
```{r norms-load, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(psych))
suppressMessages(library(bestNormalize))

urlRemote_path  <- "https://raw.githubusercontent.com/"
github_path <- "DSHerzberg/RATING-SCALE-ANALYSIS/master/INPUT-FILES/"
input_name <- "data-RS-sim-child-parent.csv"

item_prefix <- "cp"
scale_prefix <- "CP"
scale_suffix <- c("S1", "S2", "S3", "S4", "S5", "TOT")
age_range_name <- "child"
form_name <- "parent"
all_raw_range <- 10:200
TOT_raw_lower_bound <- 50
subscale_raw_upper_bound <- 40

assign(
  str_c("data", age_range_name, form_name, sep = "_"),
  suppressMessages(read_csv(url(
    str_c(urlRemote_path, github_path, input_name)
  ))) %>%
    mutate(across(
      contains(str_c(item_prefix, "i")),
      ~ case_when(
        .x == "never" ~ 1,
        .x == "occasionally" ~ 2,
        .x == "frequently" ~ 3,
        .x == "always" ~ 4
      )
    ))
)
```

<br>

###### COMMENTED SNIPPETS
Load packages for file path specification (`here`), data wrangling (`tidyverse`),  psychometric data simulation and analysis (`psych`), and normalization of raw score distributions (`bestNormalize`).
```{r norms-load, echo = 1:4, eval = F}
```
Ideally, code templates are _robust_, meaning that they can be adapted to different projects with minimal copying-and-pasting of text. Robust templates are characterized by their liberal use of _tokens_, which are names for _project-specific_ data elements that are used repeatedly in the template.

These tokenized elements include names of variables, files, test forms, raters, etc., as well as labels for age- and score ranges, score item counts, score numerical bounds, and so forth. By definition, these elements differ between, say, an autism rating-scale project and an ADHD rating-scale project. 

In contrast, the _project-general_ aspects of an R script are those functions and operations whose specification is identical for all projects (e.g., creating a table of descriptive statistics requires calling the same set of functions, regardless of whether the input data are from the autism rating scale or the ADHD rating scale). In a robust template, tokens representing project-specific elements are defined at the head of the script. The remainder of the script, therefore, consists only of project-general code.

In R, we initialize tokens as vectors. In the next code snippet, for example, `item_prefix <- "cp"` defines a vector that holds a prefix used in the names of all columns containing item responses. The snippet also includes tokens for reading a certain input file from a certain remote URL, among other project-specific elements.
```{r norms-load, echo = 5:16, eval = F}
```
Many analytic procedures require the specification of an entire set of project-specific elements, such as the entire set of item names, or form names. We can use string functions to combine tokens and explicit text as needed, both to create the names of the elements within the set, and to create the accompanying token names. For instance, we can assemble a vector containing all of the item names by concatenating the token `item_prefix` with a numerical series (e.g., `c("001", "002", "003")`). 

Often, the best token name for the resulting set of elements is itself a concatenated string. To use a concantenated string as the name of an object in R, we cannot rely on the conventional assignment operator `<-`. Instead, we use `base::assign()` to initialize these concatenated names. `assign()` takes two arguments, the desired token name (concatenated with `stringr::str_c()`), and the code snippet that defines the object(s) to be named.

As an example, `str_c("data", age_range_name, form_name, sep = "_")` returns the name `data_child_parent`, combining the file type description (`"data"`, provided as an explicit string) with the age-range (`age_range_name`) and rater (`form_name`) vectors. The combination of these latter two vectors identifies the form whose data is contained in the input file
```{r norms-load, echo = 19:20, eval = F}
```
The next snippet contains the second argument of `assign()`, which defines the data object to be named with the concatenated string. Here, an object is created by reading the input data file with `readr::read_csv()`, and recoding the item responses with `dplyr::mutate()`. Note how the input file path is a concatenation of three previously defined tokens `str_c(urlRemote_path, github_path, input_name)`.

Within `mutate()`, we use `across()` to identify and process a subset of columns. `across()` takes two arguments: the column subset, and a function to be applied to those columns. In this example, we subset the item response columns with the `tidyselect` helper `contains()`, providing as its argument a concatentated string that appears _only_ in the names of the item response columns. We use `case_when()` to conditionally recode the cell values (`.x`) of these columns, converting the input strings to numbers (e.g., `"never" ~ 1`).
```{r norms-load, echo = 21:31, eval = F}
```

<br>

#### 2. Determine optimal normalization model and calcuate normalized T-scores per case

###### EXECUTABLE CODE
```{r norms-model, eval = FALSE}
assign(str_c("data", age_range_name, form_name, "TOT", sep = "_"),
       suppressMessages(read_csv(url(
         str_c(urlRemote_path, github_path, input_name)
       ))) %>% 
         select(!!sym(str_c(scale_prefix, "TOT_raw"))) %>% 
         as_vector() %>% 
         set_names(NULL)
)

set.seed(12345)
TOT_nz_obj <- bestNormalize(data_child_parent_TOT)
TOT_nz_obj$chosen_transform
chosen_transform <- class(TOT_nz_obj$chosen_transform)

raw_score_vecs_list <-
  map(str_c(scale_prefix, scale_suffix),
      ~ get(str_c("data", age_range_name, form_name, sep = "_")) %>%
        pull(!!sym(str_c(.x, "_raw")))) %>% 
  set_names(str_c(scale_prefix, scale_suffix, "_raw"))

nzScore_perCase <- raw_score_vecs_list %>% 
  map(~ get(chosen_transform)(.x)) %>% 
  map(~ tibble(pluck(.x, "x.t"))) %>% 
  bind_cols() %>%
  set_names(str_c(scale_suffix, "_nz")) 

ntScore_perCase <- map_dfc(scale_suffix,
                           ~
                             nzScore_perCase %>%
                             transmute(!!sym(str_c(
                               scale_prefix, .x, "_nt"
                             )) := round(!!sym(str_c(
                               .x, "_nz"
                             )) * 10) + 50)) %>%
  mutate(across(
    everything(),
    ~
      case_when(. < 40 ~ 40,
                . > 80 ~ 80,
                TRUE ~ .) %>%
      as.integer(.)
  ))

assign(
  str_c("data", age_range_name, form_name, "nt", sep = "_"),
  get(str_c("data", age_range_name, form_name, sep = "_")) %>% bind_cols(ntScore_perCase) %>%
    mutate(clin_status = 'typ',
           clin_dx = NA) %>%
    select(
      ID:region,
      clin_status,
      clin_dx,
      contains("raw"),
      contains("nt"),
      everything()
    )
)

write_csv(get(str_c(
  "data", age_range_name, form_name, "nt", sep = "_"
)),
here(str_c(
  "OUTPUT-FILES/TABLES/",
  str_c("nt-Scores-per-case",
        age_range_name,
        form_name,
        sep = "-"),
  ".csv"
)),
na = '')

get(str_c("data", age_range_name, form_name, "nt", sep = "_")) %>%
  select(contains("TOT_nt")) %>%
  as_vector() %>%
  MASS::truehist(.,
                 h = 1,
                 prob = FALSE,
                 xlab = "TOT_nt")
```
###### COMMENTED SNIPPETS
The `bestNormalize` package provides tools for determining an optimal normalization model and applying that model to a raw score distribution. For the latter step, the `bestNormalize()` function requires as input the raw score distribution formatted as a numerical vector.

As in previous steps, we use `assign()` to name objects with concatenated strings. To create the numerical vector required by `bestNormalize()`, we `select()` the column containing the raw total scores for (`TOT_raw`). It is best to use a total or composite score for this purpose, because by definition a total score captures more of the sample variance than a subscale score that consists of fewer items. `select()` requires unquoted column names as input, which we provide by wrapping the concatenated column name (the quoted string returned by `str_c()`) in the unquoting function `!!sym()`.

After the `select()` line, the data object is a single-column data frame that holds the `TOT_raw` scores from the input data set. We use two functions from `purrr` to return the requisite vector formatting: `as_vector()`, which returns a named vector, and `set_names(NULL)`, which strips out the name. The raw score distribution vector `data_child_parent_TOT` is now ready for processing with `bestNormalize()`.
```{r norms-model, echo = 1:8, eval = F}
```
To ensure that `bestNormalize()` chooses the same normalizing function every time the script is run, we call `base::set.seed()` to lock down the output of R's random number generator. Calling `bestNormalize(data_parent_child_TOT)` returns a list, with the element `TOT_nz_obj$chosen_transform` holding the name of the selected normalizing function as a class attribute. To use that function in downstream code, we extract its name with `base::class()`, which returns the class attribute(s) of a list element.
```{r norms-model, echo = 10:13, eval = F}
```
Next we apply the chosen normalization function iteratively to all of the raw score distributions in the input file, including total and subscale scores. As a reminder, the normalization functions require raw score distributions to be formatted as numerical vectors (rather than data frame columns).

The next snippet extracts those vectors from the input file and places them in a list `raw_score_vecs_list`. The core function is `dplyr::pull()`, which extracts a column from a data frame and returns it as a vector. In this example, we have six raw score columns to extract, so we use `purrr::map()` to iterate over a vector that holds the six concatenated substrings that identify the target columns `str_c(scale_prefix, scale_suffix)`.

Because the name of the input file is a concatenated string `str_c("data", age_range_name, form_name, sep = "_")`, we wrap the string in `base::get()` which returns the input data frame named by the string. This data object is piped into `pull()` which requires an unquoted column name as its argument. `map()` supplies this argument by iterating over the input vector `str_c(scale_prefix, scale_suffix)`. The string elements of this vector are supplied iteratively to the call of `pull()` via the token `.x`, which `str_c()` combines with the explicit string `"_raw"` to yield a target column name. Because it is a quoted string, we need to unquote by wrapping it in `!!sym()`.

After `map()` finishes iterating, the data object is a list holding six numerical vectors (the raw score distributions). We use `set_names()` to name these elements for downstream processing.
```{r norms-model, echo = 15:19, eval = F}
```
Now we use two sequential `map()` calls to apply the chosen normalizing function to each raw score distribution, yielding a normalized z-score for each case (row). In the next snippet, we initiate the pipeline with the list of vectors to be processed `raw_score_vecs_list`. The first `map()` call iterates over this list and applies the normalizing function. We use `get()` to call the function named by `chosen_transform` and supply the `.x` token as its argument, enabling `map()` to apply the function one vector at a time. After this `map()` call finishes iterating, the data object is a list containing six `bestNormalize` normalization objects, each one itself a list named for the raw score distribution (e.g., `CPS1_raw`) whose normalized output it contains.

These normalization objects contain an element `x.t.`, which holds the distribution of normalized z-scores per case. To extract these elements, we call `purrr::pluck()`, and supply as the first argument the `.x` token, which represents the currently-iterated normalization object, and as the second argument `"x.t."`, which names the desired element. `pluck()` returns the z-score distribution as a numerical vector. We format the vector as a single-column data frame by wrapping the `pluck()` call in `tibble::tibble()`. Note the difference between `pull()`, which extracts a column from a data frame, and `pluck()`, which extracts an element from a list.

The data object is now a list of six single-column data frames, which we bind into a single data frame with `dplyr::bind_cols`. We complete the operation by applying desired column names with `set_names()`. The resulting output is a six-column data frame containing the distributions of normalized z-scores corresponding to the six raw score distributions.
```{r norms-model, echo = 21:25, eval = F}
```
